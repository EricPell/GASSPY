"""
    AUTHORS:  Loke Ohlin
    DATE: 13/04-2023
    PURPOSE:
        DatabasePopulator class:
            This class takes a skeleton database with all required models (generated by a DatabaseGenerator object) and used a ModelRunner class
            to run each model and save the resulting intensity and opacity
    USAGE:
        See test example in __name__ == "__main__"
"""


import os
import sys
import numpy as np
import time
from mpi4py import MPI
import h5py as hp
import traceback

from gasspy.io.gasspy_io import check_parameter_in_config, read_yaml
from gasspy.shared_utils.mpi_utils.mpi_print import mpi_print, mpi_all_print
from gasspy.shared_utils.mpi_utils.mpi_sync import mpi_any_sync

mpi_comm = MPI.COMM_WORLD
mpi_rank = mpi_comm.rank
mpi_size = mpi_comm.Get_size()

class DatabasePopulator(object):
    def __init__(self, 
                 gasspy_config, 
                 model_runner,
                 populator_dump_time = None,
                 est_model_time = None,
                 max_walltime = None,
                 gasspy_modeldir = None,
                 database_name = None,
                 lines_only = None
                 ) -> None:


        if isinstance(gasspy_config, str):
            self.gasspy_config = read_yaml(gasspy_config)
        else:
            self.gasspy_config = gasspy_config

        ##
        #  Name and path of hdf5 database 
        ## 

        # Name of the database which we are using
        self.database_name = check_parameter_in_config(self.gasspy_config, "database_name", database_name, "gasspy_database.hdf5") 
        
        # Path to database directory
        self.gasspy_modeldir = check_parameter_in_config(self.gasspy_config, "gasspy_modeldir", gasspy_modeldir, "gasspy_modeldir") 
        if not self.gasspy_modeldir.endswith("/"):
            self.gasspy_modeldir = self.gasspy_modeldir + "/"
        
        self.database_path = self.gasspy_modeldir+self.database_name
        # an h5database can be passed such that it can be active here and for other purposes
        try:
            self.load_database()
        except:
            mpi_all_print(traceback.format_exc())
            mpi_comm.Abort(1)  

        # Set dump timing information
        self.populator_dump_time = check_parameter_in_config(self.gasspy_config, "populator_dump_time", populator_dump_time, 1800) # Default 30 minutes
        self.est_model_time = check_parameter_in_config(self.gasspy_config, "est_model_time", est_model_time, 10) # Estimate 10 seconds per model
        self.max_walltime = check_parameter_in_config(self.gasspy_config, "max_walltime", max_walltime, 1e99) # infinte
        
        # set model_runner
        self.model_runner = model_runner

        self.save_lines = False
        # Check if we want to save lines, or if we only want to save lines
        if "line_labels" in self.gasspy_config:
            if len(self.gasspy_config["line_labels"]) > 0:
                self.N_lines = len(self.gasspy_config["line_labels"])
                self.save_lines = True
        
        self.save_spectra = not check_parameter_in_config(self.gasspy_config, "lines_only", lines_only, False)
        if self.save_spectra:
            self.N_spectral_bins = len(self.model_runner.get_energy_bins())

        # allocate buffer arrays
        self.allocate_local_buffers()

        self.local_n_complete = 0


        return

        
    def load_database(self):
        """
            Method to load database of models to populate
            input:
                h5file: h5database (optional, an active instance of an h5database)
        """
        if mpi_rank == 0: # For now only use single threaded hdf5. Should change in the future
            if not os.path.exists(self.database_path):
                sys.exit("ERROR: cannot find database %s"%self.gasspy_modeldir + self.database_name)
            h5database = hp.File(self.database_path, "r+")


        
            # Load contained fields
            fields = h5database["database_fields"][:]
            self.database_fields = []
            for field in fields:
                self.database_fields.append(field.decode())
            
            #close
            h5database.close()
        else:
            self.database_fields = None
        
        # Distribute fields to all ranks
        self.database_fields = mpi_comm.bcast(self.database_fields, root = 0)

        return

    def check_database(self):
        """
            Ensure that the database contains all required datasets, and extends the datasets if required
        """
        if mpi_rank != 0:
            return

        h5database =  hp.File(self.database_path, "r+")
        # Load models
        self.model_data = h5database["model_data"][:,:]
        self.N_unique = self.model_data.shape[0]

        # If we have populated this database before, check if we have added new models since 
        spectra_in_database = "intensity" in h5database
        lines_in_database = "line_intensity" in h5database

               
        # If we havent populated this dataset before, create room for model completion and success flags
        if not "model_completed" in h5database:
            h5database.create_dataset("model_completed" , shape = (self.N_unique,), maxshape=(None,), dtype = int)
            h5database.create_dataset("model_successful", shape = (self.N_unique,), maxshape=(None,), dtype = int)
            h5database["model_completed"] [:] = 0
            h5database["model_successful"][:] = 0

            # nothing more to do here
            return

        # If we have already started to populate this database, determine how big is the current database is, and if we need to extend it. 
        N_allocated = h5database["model_successful"].shape[0]
        if N_allocated != self.N_unique:
            # List of all fields that need to be extended
            keys = ["model_completed", "model_successful"]
            # Check if we should extend the spectra/line datasets
            if spectra_in_database or lines_in_database:
                # Make sure that if we are gonna save lines/spectra if the dataset already contains them
                if not self.save_spectra and spectra_in_database:
                    mpi_print("ERROR: Database contains spectral data, but config specifies lines_only")
                    mpi_comm.Abort(1)
                if not self.save_lines and lines_in_database:
                    mpi_print("ERROR: Database contains emission line data, but config specifies no lines")
                    mpi_comm.Abort(1)

                if self.save_spectra and spectra_in_database:
                    keys.append("intensity")
                    keys.append("opacity")
                if self.save_lines and lines_in_database:
                    keys.append("line_intensity")
                    keys.append("line_opacity")

            for key in keys:
                h5database[key].resize((self.N_unique), axis=0)
                h5database[key][N_allocated:] = 0
        h5database.close()

    def save_models(self,model_successful, gasspy_ids, intensity = None, opacity = None , line_intensity = None, line_opacity = None):
        """
            Method to save a list of models
        """
        # Only main rank does this
        if mpi_rank != 0:
            return
        
        # Open database
        h5database =  hp.File(self.database_path, "r+")

        # If this is the first time we save, we must create the dataset (since we now know the shape)
        if self.save_spectra and not "intensity" in h5database:
            h5database.create_dataset("intensity", shape = (self.N_unique, self.N_spectral_bins),maxshape=(None,self.N_spectral_bins))
            h5database.create_dataset("opacity"  , shape = (self.N_unique, self.N_spectral_bins),maxshape=(None,self.N_spectral_bins))
            # Also save energy bin information here
            h5database["energy"] = self.model_runner.get_energy_bins()
            h5database["delta_energy"] = self.model_runner.get_delta_energy_bins()     
        if self.save_lines and not "line_intensity" in h5database:
            h5database.create_dataset("line_intensity", shape = (self.N_unique, self.N_lines),maxshape=(None,self.N_lines))
            h5database.create_dataset("line_opacity"  , shape = (self.N_unique, self.N_lines),maxshape=(None,self.N_lines))
            # Also save line information here
            h5database["line_labels"] = self.model_runner.get_line_labels()
            h5database["line_energies"] = self.model_runner.get_line_energies()

        # Start by sorting since h5py is picky
        sorter = gasspy_ids.argsort()
        gasspy_ids = gasspy_ids[sorter]

        model_successful = model_successful[sorter]

        # Save these models
        if self.save_spectra:
            intensity  = intensity[sorter,:]
            opacity    = opacity[sorter,:]
            h5database["intensity"][gasspy_ids,:] = intensity
            h5database["opacity"][gasspy_ids,:] = opacity
        if self.save_lines:
            line_intensity  = line_intensity[sorter,:]
            line_opacity    = line_opacity[sorter,:]            
            h5database["line_intensity"][gasspy_ids,:] = line_intensity
            h5database["line_opacity"][gasspy_ids,:] = line_opacity    

        h5database["model_successful"][gasspy_ids] = model_successful
        h5database["model_completed"][gasspy_ids] = 1
        
        # Cloase database
        h5database.close()

    def distribute_models(self):
        """
            Method to distribute models to be run from the main rank to all ranks
        """
        self.check_database()
        if mpi_rank == 0:
            # Open database
            h5database =  hp.File(self.database_path, "r+")
            # Determine all unique models that still need to be run
            unfinished_models = np.where(h5database["model_completed"][:] == 0)[0]
            
            # How many should each rank have?
            N_unfinished = len(unfinished_models)
            N_per_rank = min(N_unfinished/mpi_size, self.n_buffered_models)
            # Distribute models and gasspy_ids to each rank
            for irank in range(1,mpi_size):
                istart = int(np.round((irank-1)*N_per_rank))
                iend = min(int(np.round((irank)*N_per_rank)),N_unfinished-1)
    
                gasspy_ids = unfinished_models[istart: iend]
                n_models_to_send = len(gasspy_ids)
                mpi_comm.send(n_models_to_send, dest = irank, tag = 0)
                if n_models_to_send == 0:
                    continue
                mpi_comm.send(gasspy_ids, dest = irank, tag = 1)
                models_to_send = self.model_data[gasspy_ids,:]
                mpi_comm.send(models_to_send, dest = irank, tag = 2)
            
            # Take remaining models as local (minimum of one)
            istart = min(int(np.round((mpi_size-1)*N_per_rank)),N_unfinished-1)

            self.gasspy_ids    = unfinished_models[istart:]
            self.models_to_run = self.model_data[self.gasspy_ids,:]

            mpi_print("\t%d models remaining"%N_unfinished)
            
            # Close database
            h5database.close()
        else:
            # Recieve models and gasspy_ids from rank 0
            n_models_to_recieve = mpi_comm.recv(source= 0, tag = 0)
            if n_models_to_recieve > 0:
                self.gasspy_ids = mpi_comm.recv(source = 0, tag = 1)
                self.models_to_run = mpi_comm.recv(source = 0, tag= 2)
            else :
                self.gasspy_ids = np.array([], dtype = int)
                self.models_to_run = np.array([], dtype = int)
    def gather_results(self):
        """
            Method to gather the results from the run models in the buffers
        """
        # Determine how many models were completed across all ranks
        n_complete_rank = np.zeros(mpi_size, dtype = int)
        n_complete_rank[:] = mpi_comm.allgather(self.local_n_complete)
        n_complete_cum = np.cumsum(n_complete_rank)
        n_complete_total = np.sum(n_complete_rank)
        
        all_intensity = None
        all_opacity = None
        all_line_intensity = None
        all_line_opacity = None

        if n_complete_total == 0:
            return
        if mpi_rank == 0:
            # Create arrays to store these models
            if self.save_spectra:
                all_intensity = np.zeros((n_complete_total, self.N_spectral_bins))
                all_opacity = np.zeros((n_complete_total, self.N_spectral_bins))
            if self.save_lines:
                all_line_intensity = np.zeros((n_complete_total, self.N_lines))
                all_line_opacity = np.zeros((n_complete_total, self.N_lines))
                                
            all_model_successful = np.zeros((n_complete_total), dtype = int)
            all_gasspy_ids = np.zeros((n_complete_total), dtype = int)

            # Set values for local completed models
            if self.local_n_complete > 0:
                if self.save_spectra:
                    all_intensity[:self.local_n_complete,:] = self.buffer_intensity[:self.local_n_complete,:]
                    all_opacity[:self.local_n_complete,:]   = self.buffer_opacity[:self.local_n_complete,:]
                if self.save_lines:
                    all_line_intensity[:self.local_n_complete,:] = self.buffer_line_intensity[:self.local_n_complete,:]
                    all_line_opacity[:self.local_n_complete,:]   = self.buffer_line_opacity[:self.local_n_complete,:]
                all_model_successful[:self.local_n_complete] = self.buffer_model_successful[:self.local_n_complete]
                all_gasspy_ids[:self.local_n_complete] = self.buffer_gasspy_ids[:self.local_n_complete]

            # Loop over all ranks and gather completed models from other ranks
            for irank in range(1, mpi_size):
                if n_complete_rank[irank] == 0:
                    continue
                if self.save_spectra:
                    all_intensity[n_complete_cum[irank-1]:n_complete_cum[irank],:] = mpi_comm.recv(source = irank, tag = 6*irank + 1)
                    all_opacity[n_complete_cum[irank-1]:n_complete_cum[irank],:] = mpi_comm.recv(source = irank, tag = 6*irank + 2)
                if self.save_lines:
                    all_line_intensity[n_complete_cum[irank-1]:n_complete_cum[irank],:] = mpi_comm.recv(source = irank, tag = 6*irank + 3)
                    all_line_opacity[n_complete_cum[irank-1]:n_complete_cum[irank],:] = mpi_comm.recv(source = irank, tag = 6*irank + 4)
                
                all_model_successful[n_complete_cum[irank-1]:n_complete_cum[irank]] = mpi_comm.recv(source = irank, tag = 6*irank + 5)
                all_gasspy_ids[n_complete_cum[irank-1]:n_complete_cum[irank]] = mpi_comm.recv(source = irank, tag = 6*irank + 6)
            
            # Save them
            mpi_print("\tdumping %d models"%n_complete_total)
            self.save_models(all_model_successful, all_gasspy_ids, 
                            intensity=all_intensity, opacity=all_opacity, 
                            line_intensity=all_line_intensity, line_opacity=all_line_opacity)

        
        else: # if not main rank
            if self.local_n_complete == 0:
                return
            if self.save_spectra:
                mpi_comm.send(self.buffer_intensity[:self.local_n_complete,:], dest = 0, tag = 6*mpi_rank + 1)            
                mpi_comm.send(self.buffer_opacity[:self.local_n_complete,:], dest = 0, tag = 6*mpi_rank + 2)            
            if self.save_lines:
                mpi_comm.send(self.buffer_line_intensity[:self.local_n_complete,:], dest = 0, tag = 6*mpi_rank + 3)            
                mpi_comm.send(self.buffer_line_opacity[:self.local_n_complete,:], dest = 0, tag = 6*mpi_rank + 4)

            mpi_comm.send(self.buffer_model_successful[:self.local_n_complete], dest = 0, tag = 6*mpi_rank + 5)            
            mpi_comm.send(self.buffer_gasspy_ids[:self.local_n_complete], dest = 0, tag = 6*mpi_rank + 6)

    def allocate_local_buffers(self):
        """
            Method to allocate the buffers
        """
        # How many do we expect?
        self.n_buffered_models = int(self.populator_dump_time/self.est_model_time) + 1
        if self.save_spectra:
            self.buffer_intensity = np.zeros((self.n_buffered_models,self.N_spectral_bins), dtype = float)
            self.buffer_opacity = np.zeros((self.n_buffered_models,self.N_spectral_bins), dtype = float)
        if self.save_lines:
            self.buffer_line_intensity = np.zeros((self.n_buffered_models,self.N_lines), dtype = float)
            self.buffer_line_opacity = np.zeros((self.n_buffered_models,self.N_lines), dtype = float)            
        self.buffer_model_successful = np.zeros(self.n_buffered_models, dtype = int)
        self.buffer_gasspy_ids = np.zeros(self.n_buffered_models, dtype = int)
        self.local_n_complete = 0
        return
    
    def reset_local_buffers(self):  
        """
            Method to reset the buffers
        """
        # if they havent been allocated, do nothing
        if self.save_spectra:
            self.buffer_intensity[:,:] = 0
            self.buffer_opacity[:,:] = 0 
        if self.save_lines:
            self.buffer_line_intensity[:,:] = 0
            self.buffer_line_opacity[:,:] = 0 

        self.buffer_model_successful[:] = 0
        self.buffer_gasspy_ids[:] = 0
        self.local_n_complete = 0
        return


    def __run_model__(self):
        """
            Runs the current model and saves its intensity/opacity
        """
        if self.local_n_complete >= len(self.models_to_run):
            # If there is nothing to run locally, do nothing
            return
        gasspy_id = self.gasspy_ids[self.local_n_complete]
        model = self.models_to_run[self.local_n_complete,:]

        # Create dictionary of fields needed for the model_runner
        model_dict = {}
        for field in self.model_runner.required_fields:
            if field not in self.database_fields:
                mpi_print("ERROR: could not find field %s required by model_runner in database"%field)
                mpi_print("Fields required by model_runner :")
                mpi_print(self.model_runner.required_fields)
                mpi_print("Fields in database :")
                mpi_print(self.database_fields)                   
                sys.exit(0)

            ifield = self.database_fields.index(field)
            model_dict[field] = model[ifield]
        
        # Send model to model_runner
        self.model_runner.run_model(model_dict, "gasspy_%d"%gasspy_id)

        # set success state and gasspy id
        self.buffer_model_successful[self.local_n_complete] = self.model_runner.model_successful()
        self.buffer_gasspy_ids[self.local_n_complete] = gasspy_id

        if self.model_runner.model_successful():   
            # Get intensity and opacity off model
            if self.save_spectra:
                self.buffer_intensity[self.local_n_complete,:] = self.model_runner.get_intensity()
                self.buffer_opacity[self.local_n_complete,:] = self.model_runner.get_opacity()
            if self.save_lines:
                self.buffer_line_intensity[self.local_n_complete,:] = self.model_runner.get_line_intensity()
                self.buffer_line_opacity[self.local_n_complete,:] = self.model_runner.get_line_opacity()
        # advance number of completed models
        self.local_n_complete += 1
        self.model_runner.clean_model()


    def __run_models__(self):
        """
            Main call to run all required models
        """
        mpi_print("Running models")
        # Distribute models from main rank
        self.distribute_models()

        # Set timers
        start_runtime = time.time()
        time_since_last_dump = time.time()
        self.local_n_complete = 0

        # Loop over all models
        all_ranks_complete = np.array([mpi_comm.allgather(0)])
        all_ranks_to_dump = np.array([mpi_comm.allgather(0)])

        self.local_n_complete = 0
        while np.any(all_ranks_complete == 0): # Run as long as any rank has something to do
            # Run the next local model
            self.__run_model__()

            # Check if we need to dump or exit the loop
            current_time = time.time()

            rank_to_dump = (current_time - start_runtime >= self.max_walltime or # max wall time reached
                            current_time - time_since_last_dump > self.populator_dump_time or # max dump intervall time reached
                            self.local_n_complete == self.n_buffered_models or # Buffer size reached or all finished
                            (self.local_n_complete == len(self.models_to_run) and len(self.models_to_run) != 0))# We have no more to run

            # Check if any rank wants to dump
            if rank_to_dump:
                all_ranks_to_dump[:] = mpi_any_sync(1)
            else:
                all_ranks_to_dump[:] = mpi_any_sync(0)

            # If any rank feels the need to dump, dump
            if np.any(all_ranks_to_dump == 1):
                self.gather_results()
                # re-distribute models, reset buffers and buffer counter
                self.reset_local_buffers() 
                self.distribute_models()
                self.local_n_complete = 0

                # Check if we are done running models after re-destributing
                if current_time - start_runtime >= self.max_walltime or len(self.models_to_run) == 0:
                    all_ranks_complete[:] = mpi_comm.allgather(1)
                else:
                    all_ranks_complete[:] = mpi_comm.allgather(0)

                # reset dump time
                time_since_last_dump = time.time()

        mpi_print("")  
    
    def run_models(self):
        """
            Main call to run all required models
        """
        try:
            self.__run_models__()
        except:
            mpi_all_print(traceback.format_exc())
            mpi_comm.Abort(1)            

    def set_max_walltime(self, max_walltime):
        self.max_walltime = max_walltime

    def __finalize__(self):
        """
            Method to safely finalize 
        """
        self.check_database()
        # only needed for rank 0
        if mpi_rank != 0:
            return
        # Open database
        h5database =  hp.File(self.database_path, "r+")
        model_completed = h5database["model_completed"][:]
        model_successful = h5database["model_successful"][:]
        print("Database contains %d models, %d have been populated with spectra, %d still need to be run"%(len(model_completed), np.sum(model_completed==1), np.sum(model_completed==0)))
        
        N_failed = np.sum(model_successful[model_completed==1]==0)
        if N_failed > 0:
            print("%d models failed. Please figure out why and if you care"%np.sum(model_successful[model_completed==1]==0))
        # Close the database
        h5database.close()

    def finalize(self):
        """
            Ensure that everything safely finalizes cleanly
        """
        try: 
            self.__finalize__()
        except:
            mpi_all_print(traceback.format_exc())
            mpi_comm.Abort(1)

####################################################################################
# TESTING
####################################################################################
"""
    testunit:
    1) Generate multiple simulation_readers with fields
    2) Add one
    3) Add the other
    4) check that it all makes sense
"""
if __name__ == "__main__":

    class ModelRunner:
        """ 
            Dummy ModelRunner class
        """
        def __init__(self):
            self.required_fields = ["var1", "var2"]
            return

        def run_model(self, model_dict, model_name):
            value = int(model_name[len("gasspy_"):])
            self.intensity = np.full(100, value) # set to the gasspy_id for easy testing
            self.opacity = np.full(100, value)
            time.sleep(1) # pretend to take 1 second per model

        def get_intensity(self):
            return self.intensity
        
        def get_opacity(self):
            return self.opacity
        
        def model_successful(self):
            return 1
        
        def get_energy_bins(self):
            return np.arange(100)
        def get_delta_energy_bins(self):
            return np.full(100,1)
        def delete_files(self):
            return
    # Simple gasspy config with needed parameters
    gasspy_config = {
        "database_name" : "test_database.hdf5",
        "gasspy_modeldir" : "./test_database/",
        "database_fields" :[ 
              "var1",
              "var2"
        ],
        "populator_dump_time" : 7, # approximatly 7 models per dump 
        "est_model_time" : 0.5 # lowball a bit
    }

    model_runner = ModelRunner()

    # Create fake data of 10 models
    N_models = 10
    if mpi_rank == 0:
        import shutil
        if os.path.exists("test_database"):
            shutil.rmtree("test_database")

        os.makedirs("test_database")
    
        # Create a fake test_database
        h5database = hp.File("test_database/test_database.hdf5", "w")
        h5database.create_dataset("model_data", shape = (N_models,2), maxshape = (None,2))

        models = np.array([np.arange(N_models),np.arange(N_models)]).T
        h5database["model_data"][:,:] = models 
        h5database["database_fields"] = ["var1" , "var2"]
        h5database.close()

    # Start by running all of them
    mpi_print("All new")
    database_populator = DatabasePopulator(gasspy_config, model_runner)
    database_populator.run_models()
    database_populator.finalize()
    
    del database_populator
    N_new_models = mpi_size * 10 # 10 new per rank
    N_old = N_models
    N_models = N_models + N_new_models
    max_walltime = 5 # limit runtime
    if mpi_rank == 0:
        # Test adding new models and also running out of walltime
        h5database = hp.File("test_database/test_database.hdf5", "r+")



        new_models = np.array([np.arange(N_models),np.arange(N_models)]).T
        h5database["model_data"].resize((N_models), axis = 0)
        h5database["model_data"][:,:] = new_models
    else:
        h5database = None

    database_populator = DatabasePopulator(gasspy_config, model_runner, max_walltime=max_walltime, h5database=h5database)
    database_populator.run_models()
    database_populator.finalize(close_hdf5=False)

    if mpi_rank == 0:
        n_not_complete = np.sum(h5database["model_completed"][:] == 0)
        for irank in range(1, mpi_size):
            mpi_comm.send(n_not_complete, dest = irank, tag = irank) 
    else:
        n_not_complete = mpi_comm.recv(source = 0, tag = mpi_rank)
    while n_not_complete> 0:
        database_populator = DatabasePopulator(gasspy_config, model_runner, max_walltime=max_walltime, h5database=h5database)
        database_populator.run_models()
        database_populator.finalize(close_hdf5=False)
        if mpi_rank == 0:
            n_not_complete = np.sum(h5database["model_completed"][:] == 0)
            for irank in range(1, mpi_size):
                mpi_comm.send(n_not_complete, dest = irank, tag = irank) 
        else:
            n_not_complete = mpi_comm.recv(source = 0, tag = mpi_rank)

    if mpi_rank == 0:
        # Make sure all models are completed and successful, and that their intensities and opacities are correctly saved
        intensity = h5database["intensity"][:,:]
        opacity = h5database["opacity"][:,:]
        model_completed = h5database["model_completed"][:]
        model_successful = h5database["model_successful"][:]    

        if np.sum(model_completed == 0) > 0:
            print("Error: not all models completed") 
        if np.sum(model_successful == 0) > 0:
            print("Error: not all models successful")

        ids = np.arange(len(model_completed))
        if np.sum(intensity[:,0]!= ids):
            print("Error: intensities do not match their ids") 
        if np.sum(opacity[:,0]!= ids):
            print("Error: opacity do not match their ids") 

        shutil.rmtree("test_database")
